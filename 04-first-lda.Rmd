---
title: "First LDA"
output: html_notebook
---

# Goals

  * Create a suitable corpus from the dataset
  * See how a simple topic model performs as a baseline for comparing other methods
  
# Corpus cleaning  

  * Perform standard cleaning, e.g. punctuation and number removal, uniform case, etc.
  * Identify a suitable set of stopwords for use throughout

# Libraries used

```{r, warning=F, message=F, error=F, comment=F}
library(dplyr)
library(stringr)
library(tm)
```

# Load the data

This section parses the zipped `posts.csv` created by [03-datafile-construction.Rmd](https://github.com/phively/uchicago-thesis/blob/master/03-datafile-construction.Rmd)

Source code: [read-PostsData-zip.R](https://github.com/phively/uchicago-thesis/blob/master/R/read-PostsData-zip.R)

```{r, message=F}
source("R/read-PostsData-zip.R")
```

# Text cleaning

```{r}
merged <- merged %>% mutate(
  # Convert everything to lower-case
  CleanBody = str_to_lower(CleanBody),
  # Replace numbers with space
  CleanBody = str_replace_all(CleanBody, "[[:digit:]]", " "),
  # Replace punctuation with space
  CleanBody = str_replace_all(CleanBody, "[[:punct:]]", " "),
  # Replace multiple whitespaces with a single space
  CleanBody = str_replace_all(CleanBody, "\\s+", " ")
)
```

# Corpus creation
