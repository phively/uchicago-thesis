---
title: "Exploration"
output: html_notebook
---

# Data description

Data was extracted from the December 15, 2016 stats.stackexchange.com [Posts table dump](https://archive.org/details/stackexchange).

# Libraries used

```{r, warning=F, message=F, error=F, comment=F}
library(xml2)
library(dplyr)
library(lubridate)
library(stringr)
library(ggplot2)
```

# Load the data

```{r}
# Grab the XML file
xml <- unzip("data/Posts.zip") %>% read_xml() # unz() crashes on me
file.remove("Posts.xml")

# Load post types dictionary
PostTypes <- read.csv("data/PostTypes.csv") %>%
  mutate(Id = as.character(Id))

# Function to grab xml fields
getXmlField <- function(part) {xml_children(xml) %>% xml_attr(part)}

# Data frame to store posts data
posts <- data.frame(stringsAsFactors = FALSE,
  Id = getXmlField("Id"),
  PostTypeId = getXmlField("PostTypeId"),
  AcceptedAnswerId = getXmlField("AcceptedAnswerId"),
  CreationDate = getXmlField("CreationDate") %>% ymd_hms(),
  Score = getXmlField("Score") %>% as.numeric(),
  ViewCount = getXmlField("ViewCount") %>% as.numeric(),
  Body = getXmlField("Body"),
#  OwnerUserId = getXmlField("OwnerUserId"),
#  LastActivityDate = getXmlField("LastActivityDate"),
  Title = getXmlField("Title"),
  Tags = getXmlField("Tags"),
  AnswerCount = getXmlField("AnswerCount") %>% as.numeric(),
  CommentCount = getXmlField("CommentCount") %>% as.numeric(),
#  FavoriteCount = getXmlField("FavoriteCount"),
#  LastEditorUserId = getXmlField("LastEditorUserId"),
#  LastEditDate = getXmlField("LastEditDate"),
#  CommunityOwnedDate = getXmlField("CommunityOwnedDate"),
  ParentId = getXmlField("ParentId")#,
#  ClosedDate = getXmlField("ClosedDate")
) %>% left_join(PostTypes, by = c("PostTypeId" = "Id"))
```

# Data exploration

## Summary stats

### How many posts?
```{r}
nrow(posts)
```

### What are the types of posts?
```{r}
posts %>% select(Name) %>% summary()
```

### How many comments per post?
```{r}
posts %>% select(CommentCount) %>% summary()
```

### How many answers per question?
```{r}
posts %>% filter(Name == "Question") %>% select(AnswerCount) %>% summary()
```

### When were posts made?
```{r}
posts %>% group_by(Name, CreationDate = round_date(CreationDate, unit = "month")) %>% summarise(Posts = length(Name)) %>%
  ggplot(aes(x = CreationDate, y = Posts, color = Name)) + geom_line() + labs(title = "Count of posts by month")
```

## Distributions

### How is Title distributed for questions?
```{r}
len_title <- data.frame(words_title = str_count({posts %>% filter(Name %in% c("Question"))}$Title, "[[:alpha:]]+"))
summary(len_title)
```

### How is Body distributed for questions and answers?
```{r}
# Id numbers of questions and answers
qa <- posts %>% filter(Name %in% c("Question", "Answer")) %>% select(Id) %>% unlist()

# Word count of question and answer posts
len_qa <- data.frame(stringsAsFactors = FALSE,
  Id = qa,
  words_qa = str_count({posts %>% filter(Id %in% qa)}$Body,
                    "[[:alpha:]]+")
)
summary(len_qa %>% select(words_qa))

# Histogram of word count (log10)
len_qa %>% ggplot(aes(x = words_qa)) + geom_histogram(binwidth = .05, alpha = .5) +
  scale_x_log10(breaks = c(0, 1, 10, 100, 1000, 10000, 100000)) +
  geom_vline(xintercept = mean(len_qa$words_qa), color = "blue", linetype = "dotted")

# Q-Q plot (log10)
len_qa$words_qa %>% log10() %>% qqnorm()
len_qa$words_qa %>% log10() %>% qqline()
```

### If we combine answers with the same ParentId with their question, how does the word count change?
```{r}
# Merged dataset; for each answer, paste Body into the Body of the question with matching Id
merged <- bind_rows(
  posts %>% filter(Name == "Question") %>% select(Id, Body), # Questions
  posts %>% filter(Name == "Answer") %>% select(Id = ParentId, Body) # Answers
) %>% group_by(Id) %>% summarise_each(funs(paste(., collapse = " ")))

# Word count of question posts with answers merged in
len_qa_merge <- data.frame(stringsAsFactors = FALSE,
  Id = merged$Id,
  words_qa_merge = str_count(merged$Body, "[[:alpha:]]+")
)
summary(len_qa_merge %>% select(words_qa_merge))

# Histogram of word count (log10)
len_qa_merge %>% ggplot(aes(x = words_qa_merge)) + geom_histogram(binwidth = .05, alpha = .5) +
  scale_x_log10(breaks = c(0, 1, 10, 100, 1000, 10000, 100000)) +
  geom_vline(xintercept = mean(len_qa_merge$words_qa_merge), color = "blue", linetype = "dotted")

# Q-Q plot (log10)
len_qa_merge$words_qa_merge %>% log10() %>% qqnorm()
len_qa_merge$words_qa_merge %>% log10() %>% qqline()
```

## Least and most "wordy" posts

### Shortest posts
```{r}
left_join(
  which(len_qa$words_qa %in% {len_qa$words_qa %>% sort() %>% head()}) %>% len_qa[., ],
  posts %>% select(Id, Body)
)
```

### Longest posts
```{r}
left_join(
  which(len_qa$words_qa %in% {len_qa$words_qa %>% sort() %>% tail()}) %>% len_qa[., ],
  posts %>% select(Id, Body)
)
```

Note that things like \<p\> and 1L are counted as words due to the use of `[[:alpha:]]+`; we'll fix this when creating the corpus.