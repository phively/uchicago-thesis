---
title: "Correlated topic models K"
output: html_notebook
---

# Goals

  * Identify a suitable number of topics $K$ to use for the CTM.

# Libraries used

```{r, warning=F, message=F, error=F, comment=F}
library(tidyverse)
library(slam)
library(stm)
library(foreach)
library(doParallel)
```

Set up parallel runs

```{r}
registerDoParallel(20)
getDoParWorkers()
```

# Load the final data

See [06-dataset-comparison.Rmd](https://github.com/phively/uchicago-thesis/blob/master/06-dataset-comparison.Rmd) for details on how the sparse matrix was generated.

```{r, message=F}
# Load sparse matrix with no tex
load(file = "data/sparse_matrix_no_tex.zip")
sparse <- readCorpus(sparse, type = "slam")
```

# CTM method without correlations

We can get a model like an LDA by enforcing a diagonal $\Sigma$ with `sigma.prior = 1` but note that the topic distribution in this model is not actually a Dirichlet.

```{r}
nc_ctm40 <- stm(sparse$documents, sparse$vocab, K = 40, init.type = "Spectral", ngroups = 7,
  control = list(maxV = length(sparse$vocab)), sigma.prior = 1)
nc_ctm40$time/60
```

# Rerun the 40 topic model as CTM

Correlated topic models relax the $\Sigma$ is diagonal constraint.

```{r}
now <- Sys.time()
ctm40 <- stm(sparse$documents, sparse$vocab, K = 40, init.type = "Spectral", ngroups = 7,
  control = list(maxV = length(sparse$vocab)))
(t40 <- Sys.time() - now)
```

# Compare diagonal and non-diagonal $\Sigma$

```{r, fig.height=8}
# Time to complete
nc_ctm40$time/60
ctm40$time/60
# Correlations
plot(topicCorr(nc_ctm40))
plot(topicCorr(ctm40))
# Most frequent topics
plot(nc_ctm40, n = 5, xlim = c(0, .1))
plot(ctm40, n = 5, xlim = c(0, .1))
```

# Other numbers of topics

That was surprisingly fast. Try every 5 as before.

```{r}
ctm5  <- stm(sparse$documents, sparse$vocab, K = 5,  init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm10 <- stm(sparse$documents, sparse$vocab, K = 10, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm15 <- stm(sparse$documents, sparse$vocab, K = 15, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm20 <- stm(sparse$documents, sparse$vocab, K = 20, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm25 <- stm(sparse$documents, sparse$vocab, K = 25, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm30 <- stm(sparse$documents, sparse$vocab, K = 30, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm35 <- stm(sparse$documents, sparse$vocab, K = 35, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm45 <- stm(sparse$documents, sparse$vocab, K = 45, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
ctm50 <- stm(sparse$documents, sparse$vocab, K = 50, init.type = "Spectral", ngroups = 7, control = list(maxV = length(sparse$vocab)))
```

# Multiple K

```{r}
now <- Sys.time()
manyK <- foreach(this.k = seq(50, 5, by = -5), .packages = "stm") %dopar% {
  output <- searchK(sparse$documents, sparse$vocab, K = this.k, init.type = "Spectral", ngroups = 7,
  proportion = .5, heldout.seed = 13316, verbose = FALSE)
  return(output$results)
}
(tK <- Sys.time() - now)
```

## searchK results

```{r, fig.height=8}
manyK <- list(results = bind_rows(manyK), call = NULL)
attr(manyK, "class") <- "searchK"
plot(manyK)
```

## Try additional K

```{r}
now <- Sys.time()
moreK <- foreach(this.k = seq(100, 55, by = -5), .packages = "stm") %dopar% {
  output <- searchK(sparse$documents, sparse$vocab, K = this.k, init.type = "Spectral", ngroups = 7,
  proportion = .5, heldout.seed = 13316, verbose = FALSE)
  return(output$results)
}
(tK2 <- Sys.time() - now)
```

```{r, fig.height=8}
tmp <- manyK
tmp$results <- rbind(bind_rows(moreK), manyK$results)
plot(tmp)
```

# Save results

```{r}
write.csv(rbind(manyK$results, bind_rows(moreK)), file = "results/ctm_holdout.csv")
```

```{r}
save(ctm5, ctm10, ctm15, ctm20, ctm25, ctm30, ctm35, ctm40, ctm45, ctm50, nc_ctm40, manyK, moreK,
     file ="results/ctm_by_5.zip", compress = "xz", compression_level = 1)
```

# Proper hold-out cross-validation

## Create holdout groups

```{r}
# Create holdout sets
N <- length(sparse$documents)
holdout1 <- make.heldout(documents = sparse$documents, vocab = sparse$vocab,
  N = N/5, proportion = 1, seed = 83319)
holdout2 <- make.heldout(documents = sparse$documents, vocab = sparse$vocab,
  N = N/5, proportion = 1, seed = 5052)
holdout3 <- make.heldout(documents = sparse$documents, vocab = sparse$vocab,
  N = N/5, proportion = 1, seed = 54551)
holdout4 <- make.heldout(documents = sparse$documents, vocab = sparse$vocab,
  N = N/5, proportion = 1, seed = 19245)
holdout5 <- make.heldout(documents = sparse$documents, vocab = sparse$vocab,
  N = N/5, proportion = 1, seed = 56423)

holdout <- list(holdout1, holdout2, holdout3, holdout4, holdout5)
```

## K = 5 through 20

```{r}
ctm_05_20 <- foreach(k = seq(5, 20, by = 5)) %:% # Loop through the K
  foreach(i = 1:5) %dopar% { # Loop through the holdout groups
    stm(holdout[[i]]$documents, holdout[[i]]$vocab, K = k, init.type = "Spectral", ngroups = 5,
      control = list(maxV = length(holdout[[i]]$vocab)))
  }

save(ctm_05_20, file = "results/ctm_05_20.zip", compress = "xz", compression_level = 1)
```

## K = 25 through 40

```{r}
ctm_25_40 <- foreach(k = seq(25, 40, by = 5)) %:% # Loop through the K
  foreach(i = 1:5) %dopar% { # Loop through the holdout groups
    stm(holdout[[i]]$documents, holdout[[i]]$vocab, K = k, init.type = "Spectral", ngroups = 5,
      control = list(maxV = length(holdout[[i]]$vocab)))
  }

save(ctm_25_40, file = "results/ctm_25_40.zip", compress = "xz", compression_level = 1)
```

## K = 45 through 60

```{r}
ctm_45_60 <- foreach(k = seq(45, 60, by = 5)) %:% # Loop through the K
  foreach(i = 1:5) %dopar% { # Loop through the holdout groups
    stm(holdout[[i]]$documents, holdout[[i]]$vocab, K = k, init.type = "Spectral", ngroups = 5,
      control = list(maxV = length(holdout[[i]]$vocab)))
  }

save(ctm_45_60, file = "results/ctm_45_60.zip", compress = "xz", compression_level = 1)
```

```{r}
test <- list()
for(i in 1:5) {
  test[[i]] <- eval.heldout(ctm_05_20[[1]][[i]], holdout[[i]]$missing)$doc.heldout
  test[[5+i]] <- eval.heldout(ctm_05_20[[2]][[i]], holdout[[i]]$missing)$doc.heldout
  test[[10+i]] <- eval.heldout(ctm_05_20[[3]][[i]], holdout[[i]]$missing)$doc.heldout
  test[[15+i]] <- eval.heldout(ctm_05_20[[4]][[i]], holdout[[i]]$missing)$doc.heldout
}

n <- length(test[[1]]) + length(test[[2]]) + length(test[[3]]) + length(test[[4]]) + length(test[[5]])
# Per-document log likelihood
ctm_heldout_lik <- unlist(test) %>% data.frame(
  K = rep(seq(5, 20, by = 5), each = n),
  lik = .
)
write.csv(nc_heldout_lik, file = "results/ctm_heldout_lik.csv", row.names = FALSE)
```

```{r}
ctm_heldout_lik %>% filter(K > 5) %>% group_by(K) %>% summarise(mean.lik = mean(lik), sem.lik = sd(lik)/sqrt(n), lci = mean.lik - sem.lik, uci = mean.lik + sem.lik) %>%
  ggplot(aes(x = K, y = mean.lik)) + geom_ribbon(aes(ymin = lci, ymax = uci), alpha = .2) + geom_line(color = "blue") +
  labs(y = "mean per-document holdout likelihood", x = "") + scale_x_continuous(breaks = seq(10, 60, by = 10))
```