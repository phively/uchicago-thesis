---
title: "LDA K-fold cross-validation part 2"
output: html_notebook
---

# Goals

  * Find the optimal number of topics using a cross-validation approach
  * Select a final LDA model using the aggressive TeX removal sparse matrix
  * Learn a bit about parallel cloud computing

Part 1, [07a-lda-kfold-xval.Rmd](https://github.com/phively/uchicago-thesis/blob/master/07a-lda-kfold-xval.Rmd), is too slow to complete locally so I'm going to parallelize the high-topic-count models on AWS.

# Libraries used

```{r, warning=F, message=F, error=F, comment=F}
library(dplyr)
library(wranglR)
library(tm)
library(slam)
library(topicmodels)
library(foreach)
library(doParallel)
```

# Load the data

See [06-dataset-comparison.Rmd](https://github.com/phively/uchicago-thesis/blob/master/06-dataset-comparison.Rmd) for details on how the sparse matrix was generated.

```{r, message=F}
# Load sparse matrix with no tex
load(file = "data/sparse_matrix_no_tex.zip")
```

# Setup

## Data

Set the number of groups $K$ and generate indices.

```{r}
# Set K
K <- 5

# Create k groups, as close to equal size as possible
set.seed(93401)
rand_ind <- KFoldXVal(1:sparse$nrow, k = K)
```

Create the functions to be used for cross-validation.

```{r}
# Cross-validation matrix generator function, split_set()
source("R/function-split_set.R")

# Parallel cross-validation function
xval <- function(dtm, index, ntopics, ...) {
  # Generate a list of models in parallel
  models <- foreach(i = 1:K, .packages = c("wranglR", "topicmodels", "slam"),
    .export = "split_set") %dopar% {
    # Data to use
    this_ind <- unlist(index)[unlist(index) %nin% index[[i]]]
    this_data <- split_set(dtm, this_ind)
    # Return a topic model
    LDA(this_data, k = ntopics, method = "VEM", control = list(...))
  }
  # Return the list of models
  return(models)
}
```

## Core initialization

Use 12 cores for the process.

```{r}
registerDoParallel(12)
getDoParWorkers()
```

# Topic modeling

## 3 topics

```{r}
gc()
now <- Sys.time()
models3 <- xval(dtm = sparse, index = rand_ind, ntopics = 3, seed = 17481, keep = 1)
(t3 <- Sys.time() - now)
save(models3, file = "results/lda_k_3.zip", compress = "xz", compression_level = 1)
```

## 5 topics

```{r}
gc()
now <- Sys.time()
models5 <- xval(dtm = sparse, index = rand_ind, ntopics = 5, seed = 74749, keep = 1)
(t5 <- Sys.time() - now)
save(models5, file = "results/lda_k_5.zip", compress = "xz", compression_level = 1)
```

## 10 topics

```{r}
gc()
now <- Sys.time()
models10 <- xval(dtm = sparse, index = rand_ind, ntopics = 10, seed = 90672, keep = 1)
(t10 <- Sys.time() - now)
save(models10, file = "results/lda_k_10.zip", compress = "xz", compression_level = 1)
```

## 15 topics

```{r}
gc()
now <- Sys.time()
models15 <- xval(dtm = sparse, index = rand_ind, ntopics = 15, seed = 53177, keep = 1)
(t15 <- Sys.time() - now)
save(models15, file = "results/lda_k_15.zip", compress = "xz", compression_level = 1)
```

## 20 topics

```{r}
gc()
now <- Sys.time()
models20 <- xval(dtm = sparse, index = rand_ind, ntopics = 20, seed = 45281, keep = 1)
(t20 <- Sys.time() - now)
save(models20, file = "results/lda_k_20.zip", compress = "xz", compression_level = 1)
```

## 25 topics

```{r}
gc()
now <- Sys.time()
models25 <- xval(dtm = sparse, index = rand_ind, ntopics = 25, seed = 86244, keep = 1)
(t25 <- Sys.time() - now)
save(models25, file = "results/lda_k_25.zip", compress = "xz", compression_level = 1)
```

## 30 topics

```{r}
gc()
now <- Sys.time()
models30 <- xval(dtm = sparse, index = rand_ind, ntopics = 30, seed = 41531, keep = 1)
(t30 <- Sys.time() - now)
save(models30, file = "results/lda_k_30.zip", compress = "xz", compression_level = 1)
```

## 35 topics

```{r}
gc()
now <- Sys.time()
models35 <- xval(dtm = sparse, index = rand_ind, ntopics = 35, seed = 68513, keep = 1)
(t35 <- Sys.time() - now)
save(models35, file = "results/lda_k_35.zip", compress = "xz", compression_level = 1)
```

## 40 topics

```{r}
gc()
now <- Sys.time()
models40 <- xval(dtm = sparse, index = rand_ind, ntopics = 40, seed = 19275, keep = 1)
(t40 <- Sys.time() - now)
save(models40, file = "results/lda_k_40.zip", compress = "xz", compression_level = 1)
```

# Perplexities

## In-sample results

```{r}
# Set up data frame and labels
perplexity <- data.frame(
  model = c(3, 5, 10, 15, 20, 25, 30, 35) %>% rep(each = K),
  fold = rep(1:K, times = 8),
  # Add time elapsed in hours
  time = c(t3, t5, t10, t15, t20, t25, t30, t35) %>% as.numeric(units = "hours") %>% rep(each = K)
)

# Calculate in-sample perplexity
in_sample = c(
  lapply(models3, FUN = perplexity) %>% unlist(),
  lapply(models5, FUN = perplexity) %>% unlist(),
  lapply(models10, FUN = perplexity) %>% unlist(),
  lapply(models15, FUN = perplexity) %>% unlist(),
  lapply(models20, FUN = perplexity) %>% unlist(),
  lapply(models25, FUN = perplexity) %>% unlist(),
  lapply(models30, FUN = perplexity) %>% unlist(),
  lapply(models35, FUN = perplexity) %>% unlist
)
perplexity <- perplexity %>% mutate(in_sample)
```

## Out-of-sample results

```{r}
# Function for out-of-sample perplexity
oos_perplexity <- function(models_list) {
  foreach (i = 1:K) %dopar% {
    perplexity(models_list[[i]], newdata = split_set(sparse, rand_ind[[i]]))
  }
}

# Calculate out-of-sample perplexity
perp3 <- oos_perplexity(models3) %>% unlist()
perp5 <- oos_perplexity(models5) %>% unlist()
perp10 <- oos_perplexity(models10) %>% unlist()
perp15 <- oos_perplexity(models15) %>% unlist()
perp20 <- oos_perplexity(models20) %>% unlist()
perp25 <- oos_perplexity(models25) %>% unlist()
perp30 <- oos_perplexity(models30) %>% unlist()
perp35 <- oos_perplexity(models35) %>% unlist()

# Append to perplexity data frame
perplexity <- perplexity %>% mutate(
  out_sample = c(perp3, perp5, perp10, perp15, perp20, perp25, perp30, perp35) %>% unlist()
)

# Save results
write.csv(perplexity, file = "results/lda_k_perp.csv", row.names = FALSE)
```